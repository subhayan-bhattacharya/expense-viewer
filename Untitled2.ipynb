{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expense_viewer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__name__': '__main__',\n",
       " '__doc__': 'Automatically created module for IPython interactive environment',\n",
       " '__package__': None,\n",
       " '__loader__': None,\n",
       " '__spec__': None,\n",
       " '__builtin__': <module 'builtins' (built-in)>,\n",
       " '__builtins__': <module 'builtins' (built-in)>,\n",
       " '_ih': ['',\n",
       "  'import csv\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\n# csv_file = \"test2.csv\"\\n# with open(csv_file, \\'w\\') as csv_file:\\n#     writer = csv.writer(csv_file, delimiter=\";\")\\n#     for row in my_dummy_csv_data:\\n#         writer.writerow(row)\\n\\npd.DataFrame(my_dummy_csv_data)',\n",
       "  'import pandas as pd\\nimport csv\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\n# csv_file = \"test2.csv\"\\n# with open(csv_file, \\'w\\') as csv_file:\\n#     writer = csv.writer(csv_file, delimiter=\";\")\\n#     for row in my_dummy_csv_data:\\n#         writer.writerow(row)\\n\\npd.DataFrame(my_dummy_csv_data)',\n",
       "  'import pandas as pd\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = \"test2.csv\"\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\npd.read_csv(\"test2.csv\")',\n",
       "  'import pandas as pd\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = \"test2.csv\"\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nif csv_file.is_file():\\n    transactions = pd.read_csv(\\n        csv_file,\\n        encoding=\"latin\",\\n        error_bad_lines=False,\\n        skiprows=4,\\n        delimiter=\\';\\',\\n        usecols=columns_to_use\\n    )\\nelse:\\n    print(f\"Could not read file : {csv_file}\")\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       "  'import pandas as pd\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = \"test2.csv\"\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       "  'import pandas as pd\\nimpprt pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       "  'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       "  'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       "  'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       "  'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()',\n",
       "  'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       "  'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()',\n",
       "  'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()\\ntransactions',\n",
       "  'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"3,300\"],\\n        [\"F\", \"Some description2\", \"150\"],\\n        [\"G\", \"Some description3\", \"200\", \"2,500.89\"],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       "  'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()\\ntransactions',\n",
       "  'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100.00\", \"3,300\"],\\n        [\"F\", \"Some description2\", \"150.20\"],\\n        [\"G\", \"Some description3\", \"200\", \"2,500.89\"],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       "  'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()\\ntransactions',\n",
       "  'from expense_viewer import *',\n",
       "  'locals()'],\n",
       " '_oh': {2:                   0                  1      2       3\n",
       "  0                 1               None   None    None\n",
       "  1                 2               None   None    None\n",
       "  2                 3               None   None    None\n",
       "  3                 4               None   None    None\n",
       "  4  Transaction Type    Payment Details  Debit  Credit\n",
       "  5                 T   Some description    100       0\n",
       "  6                 F  Some description2    150      20\n",
       "  7                 G  Some description3    200       0,\n",
       "  3:                                                1\n",
       "  0                                              2\n",
       "  1                                              3\n",
       "  2                                              4\n",
       "  3  Transaction Type;Payment Details;Debit;Credit\n",
       "  4                       T;Some description;100;0\n",
       "  5                     F;Some description2;150;20\n",
       "  6                      G;Some description3;200;0,\n",
       "  9:   Transaction Type    Payment Details  Debit  Credit\n",
       "  0                T   Some description    100       0\n",
       "  1                F  Some description2    150      20,\n",
       "  13:   Transaction Type    Payment Details  Debit  Credit\n",
       "  0                T   Some description    100     0.0\n",
       "  1                F  Some description2    150     NaN,\n",
       "  15:   Transaction Type    Payment Details  Debit Credit\n",
       "  0                T   Some description    100  3,300\n",
       "  1                F  Some description2    150    NaN,\n",
       "  17:   Transaction Type    Payment Details  Debit Credit\n",
       "  0                T   Some description  100.0  3,300\n",
       "  1                F  Some description2  150.2    NaN},\n",
       " '_dh': ['/Users/subhayanbhattacharya/Desktop/HobbyProjects/expense_viewer'],\n",
       " 'In': ['',\n",
       "  'import csv\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\n# csv_file = \"test2.csv\"\\n# with open(csv_file, \\'w\\') as csv_file:\\n#     writer = csv.writer(csv_file, delimiter=\";\")\\n#     for row in my_dummy_csv_data:\\n#         writer.writerow(row)\\n\\npd.DataFrame(my_dummy_csv_data)',\n",
       "  'import pandas as pd\\nimport csv\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\n# csv_file = \"test2.csv\"\\n# with open(csv_file, \\'w\\') as csv_file:\\n#     writer = csv.writer(csv_file, delimiter=\";\")\\n#     for row in my_dummy_csv_data:\\n#         writer.writerow(row)\\n\\npd.DataFrame(my_dummy_csv_data)',\n",
       "  'import pandas as pd\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = \"test2.csv\"\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\npd.read_csv(\"test2.csv\")',\n",
       "  'import pandas as pd\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = \"test2.csv\"\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nif csv_file.is_file():\\n    transactions = pd.read_csv(\\n        csv_file,\\n        encoding=\"latin\",\\n        error_bad_lines=False,\\n        skiprows=4,\\n        delimiter=\\';\\',\\n        usecols=columns_to_use\\n    )\\nelse:\\n    print(f\"Could not read file : {csv_file}\")\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       "  'import pandas as pd\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = \"test2.csv\"\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       "  'import pandas as pd\\nimpprt pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       "  'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       "  'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       "  'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       "  'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()',\n",
       "  'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       "  'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()',\n",
       "  'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()\\ntransactions',\n",
       "  'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"3,300\"],\\n        [\"F\", \"Some description2\", \"150\"],\\n        [\"G\", \"Some description3\", \"200\", \"2,500.89\"],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       "  'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()\\ntransactions',\n",
       "  'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100.00\", \"3,300\"],\\n        [\"F\", \"Some description2\", \"150.20\"],\\n        [\"G\", \"Some description3\", \"200\", \"2,500.89\"],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       "  'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()\\ntransactions',\n",
       "  'from expense_viewer import *',\n",
       "  'locals()'],\n",
       " 'Out': {2:                   0                  1      2       3\n",
       "  0                 1               None   None    None\n",
       "  1                 2               None   None    None\n",
       "  2                 3               None   None    None\n",
       "  3                 4               None   None    None\n",
       "  4  Transaction Type    Payment Details  Debit  Credit\n",
       "  5                 T   Some description    100       0\n",
       "  6                 F  Some description2    150      20\n",
       "  7                 G  Some description3    200       0,\n",
       "  3:                                                1\n",
       "  0                                              2\n",
       "  1                                              3\n",
       "  2                                              4\n",
       "  3  Transaction Type;Payment Details;Debit;Credit\n",
       "  4                       T;Some description;100;0\n",
       "  5                     F;Some description2;150;20\n",
       "  6                      G;Some description3;200;0,\n",
       "  9:   Transaction Type    Payment Details  Debit  Credit\n",
       "  0                T   Some description    100       0\n",
       "  1                F  Some description2    150      20,\n",
       "  13:   Transaction Type    Payment Details  Debit  Credit\n",
       "  0                T   Some description    100     0.0\n",
       "  1                F  Some description2    150     NaN,\n",
       "  15:   Transaction Type    Payment Details  Debit Credit\n",
       "  0                T   Some description    100  3,300\n",
       "  1                F  Some description2    150    NaN,\n",
       "  17:   Transaction Type    Payment Details  Debit Credit\n",
       "  0                T   Some description  100.0  3,300\n",
       "  1                F  Some description2  150.2    NaN},\n",
       " 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f9e76c69850>>,\n",
       " 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x7f9e76cadc90>,\n",
       " 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x7f9e76cadc90>,\n",
       " '_':   Transaction Type    Payment Details  Debit Credit\n",
       " 0                T   Some description  100.0  3,300\n",
       " 1                F  Some description2  150.2    NaN,\n",
       " '__':   Transaction Type    Payment Details  Debit Credit\n",
       " 0                T   Some description    100  3,300\n",
       " 1                F  Some description2    150    NaN,\n",
       " '___':   Transaction Type    Payment Details  Debit  Credit\n",
       " 0                T   Some description    100     0.0\n",
       " 1                F  Some description2    150     NaN,\n",
       " '_i': 'from expense_viewer import *',\n",
       " '_ii': 'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()\\ntransactions',\n",
       " '_iii': 'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100.00\", \"3,300\"],\\n        [\"F\", \"Some description2\", \"150.20\"],\\n        [\"G\", \"Some description3\", \"200\", \"2,500.89\"],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       " '_i1': 'import csv\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\n# csv_file = \"test2.csv\"\\n# with open(csv_file, \\'w\\') as csv_file:\\n#     writer = csv.writer(csv_file, delimiter=\";\")\\n#     for row in my_dummy_csv_data:\\n#         writer.writerow(row)\\n\\npd.DataFrame(my_dummy_csv_data)',\n",
       " 'csv': <module 'csv' from '/Users/subhayanbhattacharya/miniconda3/envs/expense-viewer/lib/python3.7/csv.py'>,\n",
       " 'my_dummy_csv_data': [[1],\n",
       "  [2],\n",
       "  [3],\n",
       "  [4],\n",
       "  ['Transaction Type', 'Payment Details', 'Debit', 'Credit'],\n",
       "  ['T', 'Some description', '100.00', '3,300'],\n",
       "  ['F', 'Some description2', '150.20'],\n",
       "  ['G', 'Some description3', '200', '2,500.89']],\n",
       " '_i2': 'import pandas as pd\\nimport csv\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\n# csv_file = \"test2.csv\"\\n# with open(csv_file, \\'w\\') as csv_file:\\n#     writer = csv.writer(csv_file, delimiter=\";\")\\n#     for row in my_dummy_csv_data:\\n#         writer.writerow(row)\\n\\npd.DataFrame(my_dummy_csv_data)',\n",
       " 'pd': <module 'pandas' from '/Users/subhayanbhattacharya/miniconda3/envs/expense-viewer/lib/python3.7/site-packages/pandas/__init__.py'>,\n",
       " '_2':                   0                  1      2       3\n",
       " 0                 1               None   None    None\n",
       " 1                 2               None   None    None\n",
       " 2                 3               None   None    None\n",
       " 3                 4               None   None    None\n",
       " 4  Transaction Type    Payment Details  Debit  Credit\n",
       " 5                 T   Some description    100       0\n",
       " 6                 F  Some description2    150      20\n",
       " 7                 G  Some description3    200       0,\n",
       " '_i3': 'import pandas as pd\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = \"test2.csv\"\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\npd.read_csv(\"test2.csv\")',\n",
       " 'columns_to_use': ['Transaction Type', 'Payment Details', 'Debit', 'Credit'],\n",
       " 'csv_file': PosixPath('test2.csv'),\n",
       " 'writer': <_csv.writer at 0x7f9e79b77230>,\n",
       " 'row': ['G', 'Some description3', '200', '2,500.89'],\n",
       " '_3':                                                1\n",
       " 0                                              2\n",
       " 1                                              3\n",
       " 2                                              4\n",
       " 3  Transaction Type;Payment Details;Debit;Credit\n",
       " 4                       T;Some description;100;0\n",
       " 5                     F;Some description2;150;20\n",
       " 6                      G;Some description3;200;0,\n",
       " '_i4': 'import pandas as pd\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = \"test2.csv\"\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nif csv_file.is_file():\\n    transactions = pd.read_csv(\\n        csv_file,\\n        encoding=\"latin\",\\n        error_bad_lines=False,\\n        skiprows=4,\\n        delimiter=\\';\\',\\n        usecols=columns_to_use\\n    )\\nelse:\\n    print(f\"Could not read file : {csv_file}\")\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       " '_i5': 'import pandas as pd\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = \"test2.csv\"\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       " '_i6': 'import pandas as pd\\nimpprt pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       " '_i7': 'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       " 'pathlib': <module 'pathlib' from '/Users/subhayanbhattacharya/miniconda3/envs/expense-viewer/lib/python3.7/pathlib.py'>,\n",
       " '_i8': 'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\", \"20\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       " '_i9': 'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions',\n",
       " 'transactions':   Transaction Type    Payment Details  Debit Credit\n",
       " 0                T   Some description  100.0  3,300\n",
       " 1                F  Some description2  150.2    NaN,\n",
       " '_9':   Transaction Type    Payment Details  Debit  Credit\n",
       " 0                T   Some description    100       0\n",
       " 1                F  Some description2    150      20,\n",
       " '_i10': 'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()',\n",
       " '_i11': 'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"0\"],\\n        [\"F\", \"Some description2\", \"150\"],\\n        [\"G\", \"Some description3\", \"200\", 0],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       " '_i12': 'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()',\n",
       " '_i13': 'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()\\ntransactions',\n",
       " '_13':   Transaction Type    Payment Details  Debit  Credit\n",
       " 0                T   Some description    100     0.0\n",
       " 1                F  Some description2    150     NaN,\n",
       " '_i14': 'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100\", \"3,300\"],\\n        [\"F\", \"Some description2\", \"150\"],\\n        [\"G\", \"Some description3\", \"200\", \"2,500.89\"],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       " '_i15': 'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()\\ntransactions',\n",
       " '_15':   Transaction Type    Payment Details  Debit Credit\n",
       " 0                T   Some description    100  3,300\n",
       " 1                F  Some description2    150    NaN,\n",
       " '_i16': 'import pandas as pd\\nimport pathlib\\nimport csv\\n\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\nmy_dummy_csv_data = [\\n        [1],\\n        [2],\\n        [3],\\n        [4],\\n        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\\n        [\"T\", \"Some description\", \"100.00\", \"3,300\"],\\n        [\"F\", \"Some description2\", \"150.20\"],\\n        [\"G\", \"Some description3\", \"200\", \"2,500.89\"],\\n    ]\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\nwith open(csv_file, \\'w\\') as csv_file:\\n    writer = csv.writer(csv_file, delimiter=\";\")\\n    for row in my_dummy_csv_data:\\n        writer.writerow(row)',\n",
       " '_i17': 'import pandas as pd\\nimport pathlib\\n\\ncsv_file = pathlib.Path(\"test2.csv\")\\n\\ncolumns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"]\\n\\n\\ntransactions = pd.read_csv(\\n    csv_file,\\n    encoding=\"latin\",\\n    error_bad_lines=False,\\n    skiprows=4,\\n    delimiter=\\';\\',\\n    usecols=columns_to_use\\n)\\n\\n    \\ntransactions.drop(transactions.tail(1).index,inplace=True)  # Attempt to drop the last row as it is not needed\\ntransactions.info()\\ntransactions',\n",
       " '_17':   Transaction Type    Payment Details  Debit Credit\n",
       " 0                T   Some description  100.0  3,300\n",
       " 1                F  Some description2  150.2    NaN,\n",
       " '_i18': 'from expense_viewer import *',\n",
       " 'get_expense_report': <function expense_viewer.main.get_expense_report(config_file_path: str, salary_statement_path: str) -> None>,\n",
       " '_i19': 'locals()'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WrongFormatError: The file Transaction-May-June-2020.csv is not in right format\n"
     ]
    }
   ],
   "source": [
    "config = \"expense_config.yaml\"\n",
    "salary = \"Transaction-May-June-2020.csv\"\n",
    "get_expense_report(config, salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_file = pathlib.Path(\"tests/test_data/yaml_test_file.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/subhayanbhattacharya/miniconda3/envs/expense-viewer/bin/python'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ruamel.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Casablanca', 'North by Northwest', \"The Man Who Wasn't There\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml = ruamel.yaml.YAML()\n",
    "with open(yaml_file, \"r\") as stream:\n",
    "    contents = yaml.load(stream)\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   foo_id\n",
       "0       1\n",
       "1       2\n",
       "2       3\n",
       "3       4\n",
       "4       5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"foo_id\": [1, 2, 3, 4, 5]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "mylist = [[1], [2], [3], [4], ['a', 'b'], ['c', 'd']]\n",
    "f = StringIO()\n",
    "csv.writer(f).writerows(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  a  b\n",
       "1  c  d"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "check = pd.DataFrame([['a', 'b'], ['c', 'd']])\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subhayan</th>\n",
       "      <th>Shaayan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subhayan  Shaayan\n",
       "0         1       10\n",
       "1         2       20\n",
       "2         3       30\n",
       "3         4       40\n",
       "4         5       50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"Subhayan\": [1, 2, 3, 4, 5], \"Shaayan\": [10, 20, 30, 40, 50]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_dummy_csv_data = [\n",
    "        [1],\n",
    "        [2],\n",
    "        [3],\n",
    "        [4],\n",
    "        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\"],\n",
    "        [\"T\", \"Some description\", \"100\", \"0\"],\n",
    "        [\"F\", \"Some description2\", \"150\", \"20\"],\n",
    "        [\"G\", \"Some description3\", \"200\", 0],\n",
    "    ]\n",
    "\n",
    "data = pd.DataFrame(my_dummy_csv_data)\n",
    "filename = 'test.csv'\n",
    "data.to_csv(filename, sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "my_dummy_csv_data = [\n",
    "        [1],\n",
    "        [2],\n",
    "        [3],\n",
    "        [4],\n",
    "        [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\", \"Value date\"],\n",
    "        [\"T\", \"Some description1\", \"100.00\", \"3,300\", \"05/18/2020\"],\n",
    "        [\"T\", \"Some description2\", \"150.00\", \"3,333\", \"06/23/2020\"],\n",
    "        [\"G\", \"Some description3\", \"200\", \"2,500.89\", \"11/18/2020\"],\n",
    "    ]\n",
    "\n",
    "csv_file = pathlib.Path(\"dummy.csv\")\n",
    "with open(csv_file, 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=\";\")\n",
    "    for row in my_dummy_csv_data:\n",
    "        writer.writerow(row)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction Type</th>\n",
       "      <th>Payment Details</th>\n",
       "      <th>Debit</th>\n",
       "      <th>Credit</th>\n",
       "      <th>Value date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>Some description1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3300</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>Some description2</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3333</td>\n",
       "      <td>2020-06-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction Type    Payment Details  Debit Credit Value date\n",
       "0                T  Some description1  100.0   3300 2020-05-18\n",
       "1                T  Some description2  150.0   3333 2020-06-23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import expense_viewer.main as main\n",
    "import pathlib\n",
    "\n",
    "file = pathlib.Path(\"dummy.csv\")\n",
    "check = main.load_details_from_expense_stmt(file)\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Transaction Type  4 non-null      object        \n",
      " 1   Payment Details   4 non-null      object        \n",
      " 2   Debit             4 non-null      float64       \n",
      " 3   Credit            4 non-null      float64       \n",
      " 4   Value date        4 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), object(2)\n",
      "memory usage: 288.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction Type</th>\n",
       "      <th>Payment Details</th>\n",
       "      <th>Debit</th>\n",
       "      <th>Credit</th>\n",
       "      <th>Value date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Credit Transfer</td>\n",
       "      <td>Some desc2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2500.89</td>\n",
       "      <td>2020-11-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction Type Payment Details  Debit   Credit Value date\n",
       "1  Credit Transfer      Some desc2  200.0  2500.89 2020-11-18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "data = {\n",
    "    \"Transaction Type\": [\"Debit Card Payment\", \"Credit Transfer\", \"Debit Card Payment\", \"Debit Card Payment\"],\n",
    "    \"Payment Details\": [\"Some desc1\", \"Some desc2\", \"Some desc3\", \"Some desc4\"],\n",
    "    \"Debit\": [100.00, 200.00, 110.10, 150.00],\n",
    "    \"Credit\": [330, 2500.89, 337.00, 333.00],\n",
    "    \"Value date\": [\n",
    "        datetime.strptime('05/18/20', '%m/%d/%y'),\n",
    "        datetime.strptime('11/18/20', '%m/%d/%y'),\n",
    "        datetime.strptime('05/14/20', '%m/%d/%y'),\n",
    "        datetime.strptime('05/14/20', '%m/%d/%y')\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.info()\n",
    "cond = df[\"Credit\"] > 2500.0\n",
    "df[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-60089fdcea36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_to_use\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Value date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#transactions[\"Value date\"] = pd.to_datetime(transactions[\"Value date\"], format=\"%m/%d/%Y\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expense-viewer/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expense-viewer/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expense-viewer/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expense-viewer/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expense-viewer/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1979\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1981\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test2.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "csv_file = pathlib.Path(\"test2.csv\")\n",
    "\n",
    "columns_to_use = [\"Transaction Type\", \"Payment Details\", \"Debit\", \"Credit\", \"Value date\"]\n",
    "\n",
    "\n",
    "transactions = pd.read_csv(\n",
    "    csv_file,\n",
    "    encoding=\"latin\",\n",
    "    error_bad_lines=False,\n",
    "    skiprows=4,\n",
    "    delimiter=';',\n",
    "    usecols=columns_to_use,\n",
    "    parse_dates=[\"Value date\"],\n",
    ")\n",
    "#transactions[\"Value date\"] = pd.to_datetime(transactions[\"Value date\"], format=\"%m/%d/%Y\")\n",
    "    \n",
    "transactions.drop(transactions.tail(1).index, inplace=True)\n",
    "transactions[\"Credit\"].fillna(\"0\", inplace=True)\n",
    "transactions[\"Debit\"].fillna(0, inplace=True)\n",
    "transactions[\"Credit\"] = transactions[\"Credit\"].apply(\n",
    "    lambda value: value.replace(\",\", \"\")\n",
    ")\n",
    "transactions[\"Debit\"] = transactions[\"Debit\"].apply(\n",
    "    lambda value: value if value >= 0 else value * -1\n",
    ")\n",
    "transactions[\"Credit\"] = transactions[\"Credit\"].astype(\"float64\")\n",
    "\n",
    "transactions.tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 67, 110, 145, 182, 218]\n",
      "No child expenses found for category Food for the month April\n",
      "No child expenses found for category Cash for the month April\n",
      "No child expenses found for category Food for the month May\n",
      "No child expenses found for category Cash for the month May\n",
      "No child expenses found for category Food for the month June\n",
      "No child expenses found for category Cash for the month June\n",
      "No child expenses found for category Food for the month July\n",
      "No child expenses found for category Cash for the month July\n",
      "No child expenses found for category Food for the month August\n",
      "No child expenses found for category Cash for the month August\n",
      "['April', 'May', 'June', 'July', 'August']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subhayan/Codes/expense-viewer/src/expense_viewer/expense/overall_expense.py:47: UserWarning: August has already been added to the child expenses...ignoring the data\n",
      "  f\"{month} has already been added to the child expenses...ignoring the data\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value date</th>\n",
       "      <th>Transaction Type</th>\n",
       "      <th>Payment Details</th>\n",
       "      <th>Debit</th>\n",
       "      <th>Credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>SEPA-Payment Salary/Pension</td>\n",
       "      <td>SALA Lohn/Gehalt LOHN / GEHALT 07/20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3373.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>SEPA-Direct Debit</td>\n",
       "      <td>305-9423758-9513968 AMZN Mktp DE 5QEXOB9UFOIVI367</td>\n",
       "      <td>22.87</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>DVB AG GIROCARD-ZAHLUNG//DRESDEN/DE 27-07-2020...</td>\n",
       "      <td>61.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>Cash Withdrawal</td>\n",
       "      <td>GA NR07106030 BLZ870700240928.07/19.45UHR DRESDEN</td>\n",
       "      <td>250.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>DVB AG GIROCARD-ZAHLUNG//DRESDEN/DE 30-07-2020...</td>\n",
       "      <td>61.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>7810 DISKA DRESDEN//DRESDEN/DE 01-08-2020T15:5...</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>7810 DISKA DRESDEN//DRESDEN/DE 01-08-2020T10:2...</td>\n",
       "      <td>12.38</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>CIGO 2246 DRESDEN//Dresden/DE 31-07-2020T10:41...</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>7810 DISKA DRESDEN//DRESDEN/DE 03-08-2020T19:4...</td>\n",
       "      <td>18.62</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2020-08-05</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>25043 SIMMEL SAGT DANKE//DRESDEN/DE 04-08-2020...</td>\n",
       "      <td>9.36</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>SEPA-Direct Debit</td>\n",
       "      <td>305-0549036-8396369 AMZN Mktp DE MI94AJ8Z1HN2C3P4</td>\n",
       "      <td>56.84</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2020-08-07</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>7810 DISKA DRESDEN//DRESDEN/DE 06-08-2020T19:5...</td>\n",
       "      <td>11.42</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>25043 SIMMEL SAGT DANKE//DRESDEN/DE 08-08-2020...</td>\n",
       "      <td>23.26</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>STEAK ROYAL//DRESDEN/DE 09-08-2020T22:24:24 Fo...</td>\n",
       "      <td>50.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>SEPA-Direct Debit</td>\n",
       "      <td>305-2535853-9008341 AMZN Mktp DE 44MQZ9TASTZEK0ZR</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>REWE SAGT DANKE. 42655632//Dresden/DE 10-08-20...</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>DECATHLON DEUTSCHLAND SE +//DRESDEN/DE 10-08-2...</td>\n",
       "      <td>58.71</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>7810 DISKA DRESDEN//DRESDEN/DE 11-08-2020T20:0...</td>\n",
       "      <td>17.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>POCO DRESDEN FIL. 39//DRESDEN/DE 11-08-2020T19...</td>\n",
       "      <td>318.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>POCO DRESDEN FIL. 39//DRESDEN/DE 13-08-2020T19...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>REWE SAGT DANKE. 42655632//Dresden/DE 14-08-20...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>REWE SAGT DANKE. 42655632//Dresden/DE 14-08-20...</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>ALDI SAGT DANKE 36 051//Dresden/DE 15-08-2020T...</td>\n",
       "      <td>4.79</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>DIRK ROSSMANN GMBH//DRESDEN/DE 14-08-2020T19:4...</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>DECATHLON DEUTSCHLAND SE +//DRESDEN/DE 14-08-2...</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>7810 DISKA DRESDEN//DRESDEN/DE 15-08-2020T19:4...</td>\n",
       "      <td>24.07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>Cash Withdrawal</td>\n",
       "      <td>GA NR07106030 BLZ870700240918.08/14.31UHR DRESDEN</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>SEPA-Standing Order</td>\n",
       "      <td>RINP Dauerauftrag Rent for apartment</td>\n",
       "      <td>614.83</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>TUKWILA SUPERMARKT//DRESDEN/DE 13-08-2020T18:2...</td>\n",
       "      <td>27.28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>25043 SIMMEL SAGT DANKE//DRESDEN/DE 18-08-2020...</td>\n",
       "      <td>9.65</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>POCO DRESDEN FIL. 39//DRESDEN/DE 18-08-2020T19...</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>7810 DISKA DRESDEN//DRESDEN/DE 20-08-2020T20:0...</td>\n",
       "      <td>28.39</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>SEPA-Standing Order</td>\n",
       "      <td>RINP Dauerauftrag 211000981912</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>PFENNIGPFEIFFER//Dresden/DE 21-08-2020T17:39:4...</td>\n",
       "      <td>5.55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>DB REISEZENTRUM//Dresden/DE 23-08-2020T12:17:1...</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>25043 SIMMEL SAGT DANKE//DRESDEN/DE 24-08-2020...</td>\n",
       "      <td>15.33</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Value date             Transaction Type  \\\n",
       "182 2020-07-28  SEPA-Payment Salary/Pension   \n",
       "183 2020-07-28            SEPA-Direct Debit   \n",
       "184 2020-07-28           Debit Card Payment   \n",
       "185 2020-07-28              Cash Withdrawal   \n",
       "186 2020-07-31           Debit Card Payment   \n",
       "187 2020-08-03           Debit Card Payment   \n",
       "188 2020-08-03           Debit Card Payment   \n",
       "189 2020-08-03           Debit Card Payment   \n",
       "190 2020-08-04           Debit Card Payment   \n",
       "191 2020-08-05           Debit Card Payment   \n",
       "192 2020-08-06            SEPA-Direct Debit   \n",
       "193 2020-08-07           Debit Card Payment   \n",
       "194 2020-08-10           Debit Card Payment   \n",
       "195 2020-08-10           Debit Card Payment   \n",
       "196 2020-08-11            SEPA-Direct Debit   \n",
       "197 2020-08-11           Debit Card Payment   \n",
       "198 2020-08-11           Debit Card Payment   \n",
       "199 2020-08-12           Debit Card Payment   \n",
       "200 2020-08-12           Debit Card Payment   \n",
       "201 2020-08-14           Debit Card Payment   \n",
       "202 2020-08-17           Debit Card Payment   \n",
       "203 2020-08-17           Debit Card Payment   \n",
       "204 2020-08-17           Debit Card Payment   \n",
       "205 2020-08-17           Debit Card Payment   \n",
       "206 2020-08-17           Debit Card Payment   \n",
       "207 2020-08-17           Debit Card Payment   \n",
       "208 2020-08-18              Cash Withdrawal   \n",
       "209 2020-08-18          SEPA-Standing Order   \n",
       "210 2020-08-18           Debit Card Payment   \n",
       "211 2020-08-19           Debit Card Payment   \n",
       "212 2020-08-19           Debit Card Payment   \n",
       "213 2020-08-21           Debit Card Payment   \n",
       "214 2020-08-24          SEPA-Standing Order   \n",
       "215 2020-08-24           Debit Card Payment   \n",
       "216 2020-08-24           Debit Card Payment   \n",
       "217 2020-08-25           Debit Card Payment   \n",
       "\n",
       "                                       Payment Details   Debit   Credit  \n",
       "182               SALA Lohn/Gehalt LOHN / GEHALT 07/20    0.00  3373.25  \n",
       "183  305-9423758-9513968 AMZN Mktp DE 5QEXOB9UFOIVI367   22.87     0.00  \n",
       "184  DVB AG GIROCARD-ZAHLUNG//DRESDEN/DE 27-07-2020...   61.50     0.00  \n",
       "185  GA NR07106030 BLZ870700240928.07/19.45UHR DRESDEN  250.00     0.00  \n",
       "186  DVB AG GIROCARD-ZAHLUNG//DRESDEN/DE 30-07-2020...   61.50     0.00  \n",
       "187  7810 DISKA DRESDEN//DRESDEN/DE 01-08-2020T15:5...    6.20     0.00  \n",
       "188  7810 DISKA DRESDEN//DRESDEN/DE 01-08-2020T10:2...   12.38     0.00  \n",
       "189  CIGO 2246 DRESDEN//Dresden/DE 31-07-2020T10:41...   30.00     0.00  \n",
       "190  7810 DISKA DRESDEN//DRESDEN/DE 03-08-2020T19:4...   18.62     0.00  \n",
       "191  25043 SIMMEL SAGT DANKE//DRESDEN/DE 04-08-2020...    9.36     0.00  \n",
       "192  305-0549036-8396369 AMZN Mktp DE MI94AJ8Z1HN2C3P4   56.84     0.00  \n",
       "193  7810 DISKA DRESDEN//DRESDEN/DE 06-08-2020T19:5...   11.42     0.00  \n",
       "194  25043 SIMMEL SAGT DANKE//DRESDEN/DE 08-08-2020...   23.26     0.00  \n",
       "195  STEAK ROYAL//DRESDEN/DE 09-08-2020T22:24:24 Fo...   50.10     0.00  \n",
       "196  305-2535853-9008341 AMZN Mktp DE 44MQZ9TASTZEK0ZR   29.85     0.00  \n",
       "197  REWE SAGT DANKE. 42655632//Dresden/DE 10-08-20...    6.10     0.00  \n",
       "198  DECATHLON DEUTSCHLAND SE +//DRESDEN/DE 10-08-2...   58.71     0.00  \n",
       "199  7810 DISKA DRESDEN//DRESDEN/DE 11-08-2020T20:0...   17.97     0.00  \n",
       "200  POCO DRESDEN FIL. 39//DRESDEN/DE 11-08-2020T19...  318.97     0.00  \n",
       "201  POCO DRESDEN FIL. 39//DRESDEN/DE 13-08-2020T19...   15.49     0.00  \n",
       "202  REWE SAGT DANKE. 42655632//Dresden/DE 14-08-20...    0.99     0.00  \n",
       "203  REWE SAGT DANKE. 42655632//Dresden/DE 14-08-20...    2.49     0.00  \n",
       "204  ALDI SAGT DANKE 36 051//Dresden/DE 15-08-2020T...    4.79     0.00  \n",
       "205  DIRK ROSSMANN GMBH//DRESDEN/DE 14-08-2020T19:4...    6.25     0.00  \n",
       "206  DECATHLON DEUTSCHLAND SE +//DRESDEN/DE 14-08-2...    6.81     0.00  \n",
       "207  7810 DISKA DRESDEN//DRESDEN/DE 15-08-2020T19:4...   24.07     0.00  \n",
       "208  GA NR07106030 BLZ870700240918.08/14.31UHR DRESDEN  100.00     0.00  \n",
       "209               RINP Dauerauftrag Rent for apartment  614.83     0.00  \n",
       "210  TUKWILA SUPERMARKT//DRESDEN/DE 13-08-2020T18:2...   27.28     0.00  \n",
       "211  25043 SIMMEL SAGT DANKE//DRESDEN/DE 18-08-2020...    9.65     0.00  \n",
       "212  POCO DRESDEN FIL. 39//DRESDEN/DE 18-08-2020T19...   40.00     0.00  \n",
       "213  7810 DISKA DRESDEN//DRESDEN/DE 20-08-2020T20:0...   28.39     0.00  \n",
       "214                     RINP Dauerauftrag 211000981912   40.00     0.00  \n",
       "215  PFENNIGPFEIFFER//Dresden/DE 21-08-2020T17:39:4...    5.55     0.00  \n",
       "216  DB REISEZENTRUM//Dresden/DE 23-08-2020T12:17:1...   21.50     0.00  \n",
       "217  25043 SIMMEL SAGT DANKE//DRESDEN/DE 24-08-2020...   15.33     0.00  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from expense_viewer import *\n",
    "check = get_expense_report(config_file_path=\"expense_config.yaml\", salary_statement_path=\"Transactions.csv\")\n",
    "print(check.get_child_expense_labels())\n",
    "# check.show_expense_summary_graph()\n",
    "check.child_expenses['August'].expense\n",
    "# check.child_expenses['June'].child_expenses['Retail'].get_child_expense_labels()\n",
    "# check.child_expenses['June'].child_expenses['Retail'].child_expenses['Amazon'].expense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Months'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "     \"Months\": [\"January\", \"February\", \"March\", \"April\"],\n",
    "     \"Expenses\": [2000, 3000, 1500, 7500],\n",
    "     \"Savings\": [3000, 2000, 2500, 1700]\n",
    "    }\n",
    ")\n",
    "df.plot.bar(x=\"Months\", y=\"Expenses\", color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "names = [\"Subhayan\", \"Shaayan\", \"Rohan\", \"Dimpu\"]\n",
    "check = np.arange(len(names))\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'Value date': [\n",
    "        datetime.strptime('05/14/20', '%m/%d/%y'),\n",
    "        datetime.strptime('05/12/20', '%m/%d/%y'),\n",
    "        datetime.strptime('04/11/20', '%m/%d/%y'),\n",
    "        datetime.strptime('03/10/20', '%m/%d/%y')\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "months = df[\"Value date\"].dt.month\n",
    "months.value_counts().idxmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEGCAYAAAB8Ys7jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAATmklEQVR4nO3df5DcdX3H8dcL2MtZQsZIfpByMQk1JUMghPQGsMqUGGyCDgRnIiF1MIzESCWNMFCbATtuR2yVVmgZqRqFSWpBOFEGVIQ6EKW2DCWhISRSBWmQiyE5IsEA5W4T3v3jvhfP847d7H539z7Z52PmZvf73e/n+31v7u5133z2u+91RAgAkJ4jml0AAKA6BDgAJIoAB4BEEeAAkCgCHAASdVQjDzZhwoSYPn16Iw8JAMnbtGnTixExcej6hgb49OnTtXHjxkYeEgCSZ/u54dYzhQIAiSLAASBRBDgAJKqhc+AAUI1SqaTu7m69/vrrzS6lrtrb29XR0aFCoVDR9gQ4gFGvu7tbxxxzjKZPny7bzS6nLiJCe/bsUXd3t2bMmFHRGKZQAIx6r7/+uo499tjDNrwlybaOPfbYQ/pfRtkAt91u+79sP2F7m+2/ydbPsP2o7Wds32m7rYbaAeBNHc7hPeBQn2MlZ+C9kt4TEadKmitpke0zJX1e0o0R8Q5JL0m69NBKBQDUomyAR79XssVC9hWS3iPprmz9ekkX1KNAABiqVOob1fsbzrXXXqupU6dq7Nixue2zohcxbR8paZOkd0i6WdLPJe2NiP3ZJt2Sjh9h7EpJKyXp7W9/e631tqxSqU+FQvWzVLWOB0aTQqFNxdWX5La/4k3rctvXUBGhiNB5552nVatWaebMmbntu6IAj4gDkubafqukuyXNqvQAEbFW0lpJ6uzs5ON/qlTrD2w9f0CBVrBmzRpNnTpVl19+uSSpWCzqqKOO0oYNG/TSSy+pVCrpuuuu0+LFi7V9+3YtXLhQZ5xxhjZt2qT77rtPZ555Zu41HdJVKBGxV9IGSe+U9FbbA38AOiTtyLc0ABg9li5dqq6uroPLXV1dWr58ue6++249/vjj2rBhg6666ioNfEzl008/rY9//OPatm2bpk2bVpeayp6B254oqRQRe22/RdJ71f8C5gZJSyTdIWm5pHvqUiEAjAKnnXaadu/erV/+8pfq6enR+PHjddxxx+nKK6/Uww8/rCOOOEI7duzQrl27JEnTpk2ry1n3YJVMoUyRtD6bBz9CUldEfNf2TyTdYfs6Sf8t6ZY61gkATffBD35Qd911l1544QUtXbpUt912m3p6erRp0yYVCgVNnz794HXcRx99dN3rKRvgEbFF0mnDrH9W0un1KAoARqOlS5fqox/9qF588UX96Ec/UldXlyZNmqRCoaANGzboueeG7fpaN7yVHkBySqW+XF+Yr/QqrdmzZ2vfvn06/vjjNWXKFH3oQx/Seeedp1NOOUWdnZ2aNWvk6zs++clP6vbbb9drr72mjo4OrVixQsVisaa6CfAK9Zb6NKaGy/BqHQ/gN/K+JPZQ9vfkk08evD9hwgQ98sgjw263devW31q+/vrrdf3111dX4AgI8AqNKbRpTnF51eO3FNfnWA0A0MwKAJJFgANAoghwAEgUAQ4AiSLAASBRLRPgfaXeZpcAICd5/z7XOx9ee+01vf/979esWbM0e/ZsrVmzJpf9tsxlhG2FMbqwOKfq8V3FLTlWA6AWtf4+D1XP3++B5lZXX3215s+fr76+Pi1YsEDf//73de6559a075Y5AweAWqxZs0Y333zzweVisajrrrtOCxYs0Lx583TKKafonnv6e/pt375dJ554oj784Q/r5JNPVk9Pj+bPny9Jamtr07x589Td3V1zTQQ4AFQgr3aye/fu1Xe+8x0tWLCg5ppaZgoFAGqRRzvZ/fv3a9myZVq9erVOOOGEmmsiwAGgQrW2k125cqVmzpypK664Ipd6CHAAqFAt7WQ/9alP6eWXX9bXvva13OohwAEkp6/Um+uVI32lXrUVxpTdrtp2st3d3frsZz+rWbNmad68eZKkVatWacWKFTXVTYADSE4lYVuv/VXTTrajo+Pgi5t54ioUAEgUAQ4AiSLAASBRBDgAJIoAB4BEEeAAkCgCHEByekt9o3p/w1m0aJFOPfVUzZ49W5dddpkOHDhQ8z65DhxAcsYU2jSnuDy3/W0prs9tX0NFhCJCXV1dGjdunCJCS5Ys0Te/+U1ddNFFNe277Bm47am2N9j+ie1ttj+RrS/a3mF7c/b1vpoqAYBRrJZ2ss8//7zGjRsnqb+hVV9fn2zXXFMlUyj7JV0VESdJOlPS5bZPyh67MSLmZl/31VwNAIxSebSTXbhwoSZNmqRjjjlGS5YsqbmmsgEeETsj4vHs/j5JT0k6vuYjA0BCBreTfeKJJw62k73mmms0Z84cnXPOOWXbyT7wwAPauXOnent79dBDD9Vc0yG9iGl7uqTTJD2arVple4vtW22PH2HMStsbbW/s6emprVoATVHri3yNeJGwEQbayd55552/00528+bNmjx58pu2k5Wk9vZ2LV68+OB0Sy0qfhHT9lhJ35J0RUT82vaXJH1GUmS3X5D0kaHjImKtpLWS1NnZmX83FwB1V+uLhvV8kbCRqm0n+8orr2jfvn2aMmWK9u/fr+9973s666yzaq6nogC3XVB/eN8WEd+WpIjYNejxr0r6bs3VAEAFekt9uf5R6C31aUyhrex21baTffXVV3X++eert7dXb7zxhubPn6/LLrus5rrLBrj7Xyq9RdJTEXHDoPVTImJntvgBSVuHGw8AeaskbOu1v2rayU6ePFmPPfZY9QWOoJIz8HdJuljSk7Y3Z+uukbTM9lz1T6Fsl/Sx3KsDAIyobIBHxI8lDXfBIpcNAkAT8VZ6AEmoxyfajDaH+hwJcKACXEbXXO3t7dqzZ89hHeIRoT179qi9vb3iMfRCASrAZXTN1dHRoe7ubh3u7yVpb29XR0dHxdsT4ABGvUKhoBkzZjS7jFGHKRQASBQBDgCJIsABIFEEOAAkigAHgEQR4ACQKAIcABJFgANAoghwAEgUAQ4AiSLAASBRBDiAUa9UYzfHWsePVjSzAjDqFQptKq6+pOrxxZvW5VbLaMIZOAAkigAHgEQR4ACQKAIcABJFgANAoghwAEgUAQ4AiSLAASBRBDgAJKpsgNueanuD7Z/Y3mb7E9n6t9n+ge2ns9vx9S8XADCgkjPw/ZKuioiTJJ0p6XLbJ0laI+nBiJgp6cFsGQDQIGUDPCJ2RsTj2f19kp6SdLykxZLWZ5utl3RBnWoEAAzjkObAbU+XdJqkRyVNjoid2UMvSJo8wpiVtjfa3tjT01NLrQCAQSoOcNtjJX1L0hUR8evBj0VESIrhxkXE2ojojIjOiRMn1lQsAOA3Kgpw2wX1h/dtEfHtbPUu21Oyx6dI2l2fEgEAw6nkKhRLukXSUxFxw6CH7pW0PLu/XNI9+ZcHABhJJR/o8C5JF0t60vbmbN01kj4nqcv2pZKek3RhXSoEAAyrbIBHxI8leYSHF+RbDgCgUrwTEwASRYADQKIIcABIFAEOAIkiwAEgUQQ4ACSKAAeARBHgAJAoAhwAEkWAA0CiCHAASBQBDgCJIsABIFEEOAAkigAHgAr0lvqaOn44lXygAwC0vDGFNs0pLi+/4Qi2FNfnWE0/zsABIFEEOAAkigAHgEQR4ACQKAIcABJFgKMl9JV6m10CkDsuI0RLaCuM0YXFOVWP7ypuybEaIB+cgQNAoghwAEhU2QC3favt3ba3DlpXtL3D9ubs6331LRMAMFQlZ+DrJC0aZv2NETE3+7ov37IAAOWUDfCIeFjSrxpQCwDgENQyB77K9pZsimX8SBvZXml7o+2NPT09NRwOADBYtQH+JUl/IGmupJ2SvjDShhGxNiI6I6Jz4sSJVR4OADBUVQEeEbsi4kBEvCHpq5JOz7csAEA5VQW47SmDFj8gaetI2wIA6qPsOzFtf0PS2ZIm2O6W9GlJZ9ueKykkbZf0sfqVCAAYTtkAj4hlw6y+pQ61AAAOAe/EBIBEEeAAkCgCHAASRYADQKIIcABIFAEOAIkiwAEgUQQ4ACSKAAeARBHgAJAoAhwAEkWAA0CiCHAASBQBDgCJIsABIFHJBHip1NfsEgBgVCn7gQ6jRaHQpuLqS6oeX7xpXW61AMBokMwZOADgtxHgAJAoAhwAEkWAA0CiCHAASBQBDgCJIsABIFEEOAAkigAHgESVDXDbt9rebXvroHVvs/0D209nt+PrWyYAYKhKzsDXSVo0ZN0aSQ9GxExJD2bLAIAGKhvgEfGwpF8NWb1Y0vrs/npJF+RbFgCgnGrnwCdHxM7s/guSJo+0oe2Vtjfa3tjT01Pl4QCgen2l3maXUBc1dyOMiLAdb/L4WklrJamzs3PE7QCgXtoKY3RhcU5N++gqbsmpmvxUewa+y/YUScpud+dXEgCgEtUG+L2Slmf3l0u6J59yAACVquQywm9IekTSiba7bV8q6XOS3mv7aUnnZMsAgAYqOwceEctGeGhBzrUAAA4B78QEgEQR4ACQKAIcABJFgANAoghwAEgUAQ4AiSLAASBRBDgAJIoABxJQKvU1dTxGp5q7EQKov0KhTcXVl1Q9vnjTutxqwejBGTgAJIoAB4BEEeAAkCgCHAASRYADQKIIcABIFAEOAIkiwAEgUQQ4ACSKAAeARBHgAJAoArxF9JV6mzoeQP5oZtUi2gpjdGFxTtXju4pbcqwGQB44AweARBHgAJComqZQbG+XtE/SAUn7I6Izj6IAAOXlMQc+PyJezGE/AIBDwBQKACSq1gAPSf9me5PtlcNtYHul7Y22N/b09NR4OADV4DLQw1OtUyjvjogdtidJ+oHt/4mIhwdvEBFrJa2VpM7OzqjxeACqwGWkh6eazsAjYkd2u1vS3ZJOz6MoAEB5VQe47aNtHzNwX9KfStqaV2EAgDdXyxTKZEl32x7Yz+0RcX8uVQEAyqo6wCPiWUmn5lgLAOAQcBkhACSKAAeARBHgAJAoAhwAEkWAA0CiCHAASBQBDgCJIsABIFEEOCrSW+pr6ngAv4sPNUZFxhTaNKe4vOrxW4rrc6wGgMQZOAAkiwAHgEQR4ACQKAIcABJFgANAoghwAEgUAQ4AiSLAASBRBDgAJIoAB4BEEeAAkCgCHAASRYAjCSW6GQK/g26ESEKh0Kbi6kuqHl+8aV1utQCjBWfgAJAoAhwAElVTgNteZPuntp+xvSavogAA5VUd4LaPlHSzpHMlnSRpme2T8ioMAPDmajkDP13SMxHxbET0SbpD0uJ8ygIAlOOIqG6gvUTSoohYkS1fLOmMiFg1ZLuVklZmiydK+mn15dbVBEkvNruIJuL58/xb+flLo/vfYFpETBy6su6XEUbEWklr632cWtneGBGdza6jWXj+PP9Wfv5Smv8GtUyh7JA0ddByR7YOANAAtQT4Y5Jm2p5hu03SRZLuzacsAEA5VU+hRMR+26skPSDpSEm3RsS23CprvFE/zVNnPP/W1urPX0rw36DqFzEBAM3FOzEBIFEEOAAkigCXZPsC22F7VrNraTTbB2xvtv2E7cdt/3Gza2ok28fZvsP2z21vsn2f7T9sdl2NMuj7vy37GbjKdsvkwqDnP/CVVEsQ5sAl2b5T0u9LeigiPt3sehrJ9isRMTa7v1DSNRHxJ00uqyFsW9J/SlofEV/O1p0qaVxE/HtTi2uQId//SZJul/QfrfJ7MPj5p6hl/tKOxPZYSe+WdKn6L4VsZeMkvdTsIhpovqTSQHhLUkQ80SrhPVRE7Fb/u6ZXZX/cMMrxgQ79/Vvuj4if2d5j+48iYlOzi2qgt9jeLKld0hRJ72luOQ11sqRW+l6XFRHPZo3qJkna1ex6GmDg53/A30XEnc0q5lAR4NIySf+U3b8jW26lX+r/i4i5kmT7nZL+xfbJwdwaWsPBn/8UtXSA236b+s84T7Ed6n9DUtj+y1YMsIh4xPYESRMl7W52PQ2wTdKSZhcxmtg+QdIBtcb3P3mtPge+RNLXI2JaREyPiKmS/lfSWU2uqymyq3COlLSn2bU0yEOSxmQdMyVJtufYbtXv/0RJX5b0xVY8gUlRS5+Bq3+65PND1n0rW/9w48tpisFzgJa0PCIONLGehomIsP0BSf9o+68kvS5pu6QrmllXgw18/wuS9kv6uqQbmlpRYw2dA78/IpK5lJDLCAEgUa0+hQIAySLAASBRBDgAJIoAB4BEEeAAkCgCHAASRYCj5WS9PoDkEeA4bGS9rF/Meluvy3q8X2J7u+1Xbf+z7ZfV3zrh3bYftf2K7WcG3o1p++xs3Bez5S9my2dny2H7Z7b/1fberH/4+KY9abQ0AhyHhayP9z+ov4PeTZIWDtnk99Tf8/1qST2S7pU0LVveLekrtivtxDhT0nOSuiSdK+mva60fqAYBjsPF2dntjRHxFUm3DrPN8oj4qqTTJI2XdEvWC3zgwwvOrfBY3RFxraRVkt4YdGygoQhwHG5G6g3xakS8PMK2g8cM9IEZ6BP01pzqAnLX6s2scPj4YXZ7pe2jJH3kTbZ9RP2fPHSp7eclXZytv0/9UyOSdLbtP5N03jDjO2z/raQJ6j8J+uEw2wB1xxk4DgsR8YT657OPk/TnkgY+Fm3vMNvukXS+pF+ov/PecZI+FhEbIuIXkv5e/fPlf6H+z8wc6meSOiRdKOl+SZ/J87kAlaIbIQ4bti9Tfz/3seoP4YmSZkbECzkeIyRti4iT89onUC2mUHA4eZf6g1uStkpakWd4A6MNZ+AAkCjmwAEgUQQ4ACSKAAeARBHgAJAoAhwAEvX/nV3aH+PHWGsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# set width of bar\n",
    "barWidth = 0.25\n",
    " \n",
    "# set height of bar\n",
    "bars1 = [12, 30, 1, 8, 22]\n",
    "bars2 = [28, 6, 16, 5, 10]\n",
    "bars3 = [29, 3, 24, 25, 17]\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, bars1, color='#7f6d5f', width=barWidth, edgecolor='white', label='var1')\n",
    "plt.bar(r2, bars2, color='#557f2d', width=barWidth, edgecolor='white', label='var2')\n",
    "plt.bar(r3, bars3, color='#2d7f5e', width=barWidth, edgecolor='white', label='var3')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('group', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], ['A', 'B', 'C', 'D', 'E'])\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-409.9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import expense_viewer.expense.overall_expense as overall\n",
    "from datetime import datetime\n",
    "\n",
    "data = {\n",
    "        \"Transaction Type\": [\n",
    "            \"Debit Card Payment\",\n",
    "            \"Credit Transfer\",\n",
    "            \"Debit Card Payment\",\n",
    "            \"Debit Card Payment\",\n",
    "        ],\n",
    "        \"Payment Details\": [\"Some desc1\", \"Some desc2\", \"Some desc3\", \"Some desc4\"],\n",
    "        \"Debit\": [100.00, 200.00, 110.10, 150.00],\n",
    "        \"Credit\": [330, 2500.89, 337.00, 333.00],\n",
    "        \"Value date\": [\n",
    "            datetime.strptime(\"05/18/20\", \"%m/%d/%y\"),\n",
    "            datetime.strptime(\"11/18/20\", \"%m/%d/%y\"),\n",
    "            datetime.strptime(\"05/14/20\", \"%m/%d/%y\"),\n",
    "            datetime.strptime(\"05/14/20\", \"%m/%d/%y\"),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "config = {\n",
    "        \"salary\": {\n",
    "            \"logical_operator\": \"OR\",\n",
    "            \"identifiers\": [\n",
    "                {\"value\": 2500.00, \"comparison_operator\": \">\", \"column\": \"Credit\"}\n",
    "            ],\n",
    "        },\n",
    "        \"expense_categories\": [],\n",
    "    }\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "obj = overall.OverallExpense(\n",
    "        expenses=data, config=config\n",
    "    )\n",
    "obj.add_child_expenses()\n",
    "child = obj.child_expenses[0].expense\n",
    "#obj.child_expenses[0].label\n",
    "\n",
    "sample = {\n",
    "        \"Transaction Type\": [\"Debit Card Payment\", \"Debit Card Payment\"],\n",
    "        \"Payment Details\": [\"Some desc3\", \"Some desc4\"],\n",
    "        \"Debit\": [110.1, 150.0],\n",
    "        \"Credit\": [337.0, 333.0],\n",
    "        \"Value date\": [\n",
    "            datetime.strptime(\"05/14/20\", \"%m/%d/%y\"),\n",
    "            datetime.strptime(\"05/14/20\", \"%m/%d/%y\"),\n",
    "        ],\n",
    "        \"Indexes\": [2, 3]\n",
    "    }\n",
    "\n",
    "sample_pd = pd.DataFrame(sample)\n",
    "sample_pd.set_index(\"Indexes\", inplace=True)\n",
    "\n",
    "child.equals(sample_pd)\n",
    "obj.child_expenses[0].show_total_expense_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction Type</th>\n",
       "      <th>Payment Details</th>\n",
       "      <th>Debit</th>\n",
       "      <th>Credit</th>\n",
       "      <th>Value date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>Some desc3</td>\n",
       "      <td>110.1</td>\n",
       "      <td>337.0</td>\n",
       "      <td>2020-05-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Debit Card Payment</td>\n",
       "      <td>Some desc4</td>\n",
       "      <td>150.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>2020-05-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Transaction Type Payment Details  Debit  Credit Value date\n",
       "0  Debit Card Payment      Some desc3  110.1   337.0 2020-05-14\n",
       "1  Debit Card Payment      Some desc4  150.0   333.0 2020-05-14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUBHAYAN Bhattacharya'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class Person(NamedTuple):\n",
    "    name: str\n",
    "    lastname: str\n",
    "        \n",
    "    def capitalize(self):\n",
    "        return f\"{self.name.upper()} {self.lastname.capitalize()}\"\n",
    "        \n",
    "p = Person(name=\"Subhayan\", lastname=\"Bhattacharya\")\n",
    "p.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expense-viewer",
   "language": "python",
   "name": "expense-viewer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
